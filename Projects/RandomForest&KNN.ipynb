{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do random forest training and testing\n",
    "\n",
    "• provide accuracy, confusion matrix and classification report.\n",
    "\n",
    "• interpret the classification report.\n",
    "\n",
    "• Assess feature importance\n",
    "\n",
    "• Pick one small decision tree from the random forest and explain it\n",
    "\n",
    "• Use the top five important features to do a decision tree model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns],      PassengerId  Pclass                                          Name  \\\n",
      "0            892       3                              Kelly, Mr. James   \n",
      "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
      "2            894       2                     Myles, Mr. Thomas Francis   \n",
      "3            895       3                              Wirz, Mr. Albert   \n",
      "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "..           ...     ...                                           ...   \n",
      "413         1305       3                            Spector, Mr. Woolf   \n",
      "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
      "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
      "416         1308       3                           Ware, Mr. Frederick   \n",
      "417         1309       3                      Peter, Master. Michael J   \n",
      "\n",
      "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
      "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
      "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
      "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
      "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
      "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
      "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
      "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
      "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
      "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
      "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
      "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
      "\n",
      "[418 rows x 11 columns]]\n"
     ]
    }
   ],
   "source": [
    "# Imports needed for the script\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import re  # For regular expression operations (if needed)\n",
    "import seaborn as sns  # Seaborn for data visualization\n",
    "import matplotlib.pyplot as plt  # For plotting graphs and visualizations\n",
    "\n",
    "# For inline plotting in Jupyter Notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Plotly for interactive visualizations\n",
    "import plotly.offline as py  \n",
    "py.init_notebook_mode(connected=True)  # Initialize Plotly in notebook mode for interactive visualizations\n",
    "import plotly.graph_objs as go  # Graph objects for building plots\n",
    "import plotly.tools as tls  # Tools for Plotly visualizations\n",
    "\n",
    "# Sklearn imports for machine learning tasks\n",
    "from sklearn import tree  # Decision tree algorithms\n",
    "from sklearn.metrics import accuracy_score  # To calculate accuracy of the model\n",
    "from sklearn.model_selection import KFold  # For K-fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score  # To calculate cross-validation score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For displaying images and performing system calls\n",
    "from IPython.display import Image as PImage  # To display images in Jupyter Notebook\n",
    "from subprocess import check_call  # To run system commands, if needed\n",
    "from PIL import Image, ImageDraw, ImageFont  # Python Imaging Library for image processing\n",
    "\n",
    "# Loading the data\n",
    "train = pd.read_csv('train.csv')  # Loading the training data from CSV file\n",
    "test = pd.read_csv('test.csv')  # Loading the test data from CSV file\n",
    "\n",
    "# Store our test passenger IDs for easy access\n",
    "PassengerId = test['PassengerId']  # Storing PassengerId from the test dataset for later use\n",
    "\n",
    "full_data = [train, test]\n",
    "print(full_data)  # Displaying the first 3 rows of the training dataset to inspect the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare features and target\n",
    "original_train = train.copy() # Using 'copy()' allows to clone the dataset, creating a different object with the same values\n",
    "\n",
    "# creates a list named full_data that contains both the train and test datasets.\n",
    "full_data = [train, test]\n",
    "\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "#This block creates a new feature called Has_Cabin in both train and test datasets\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we creates a deep copy of the train dataset and stores it in a variable called original_train.\n",
    "#a backup of the original data. If you later modify the train dataset and need to reference the unmodified version, you can use original_train.\n",
    "original_train = train.copy() # Using 'copy()' allows to clone the dataset, creating a different object with the same values\n",
    "\n",
    "# creates a list named full_data that contains both the train and test datasets.\n",
    "full_data = [train, test]\n",
    "\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "#This block creates a new feature called Has_Cabin in both train and test datasets\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "for dataset in full_data:\n",
    "    dataset['Has_Cabin'] = dataset[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "# Handle missing values for Age, Fare, and Embarked\n",
    "for dataset in full_data:\n",
    "    dataset['Age'] = dataset['Age'].fillna(dataset['Age'].median())\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')  # Fill missing 'Embarked' values with the most common port\n",
    "\n",
    "    # Mapping 'Embarked' from categorical strings to integers\n",
    "    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "\n",
    "    # Mapping 'Sex' from categorical strings to integers\n",
    "    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(r' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Extract titles and group rare titles into a single category\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr',\n",
    "                                                 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# Mapping 'Title' from categorical strings to integers\n",
    "title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping).fillna(0).astype(int)\n",
    "\n",
    "# Mapping Fare and Age into discrete intervals (binning)\n",
    "for dataset in full_data:\n",
    "    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n",
    "    dataset.loc[dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "# Prepare data for training\n",
    "x_train = train.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch'], axis=1)\n",
    "y_train = train['Survived']\n",
    "x_test = test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch'], axis=1)\n",
    "\n",
    "# Random Forest Classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "random_forest.fit(x_train, y_train)  # Fit the model using the training data\n",
    "\n",
    "# Predicting results for the test dataset\n",
    "y_pred_rf = random_forest.predict(x_test)\n",
    "\n",
    "# Store results in a DataFrame and export to CSV for submission\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test['PassengerId'],\n",
    "        \"Survived\": y_pred_rf\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare feature and target\n",
    "# Feature selection: remove variables no longer containing relevant information\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "test  = test.drop(drop_elements, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After ensuring no missing values, now fit the model to x_train and y_train\n",
    "# Random Forest Classifier (as an example)\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=5,random_state=1)\n",
    "random_forest.fit(x_train, train['Survived'])  # Fit model using training data\n",
    "\n",
    "# Predict using x_test\n",
    "y_pred_rf = random_forest.predict(x_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict results on test data\n",
    "y_pred_rf = random_forest.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raandom Forest Accuracy: 84.18%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate accuracy\n",
    "train_pred_rf = random_forest.predict(x_train)\n",
    "acc_random_forest=round(accuracy_score(y_train, train_pred_rf)*100, 2)\n",
    "\n",
    "print(f\"Raandom Forest Accuracy: {acc_random_forest}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix, and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[495  54]\n",
      " [ 87 255]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       549\n",
      "           1       0.83      0.75      0.78       342\n",
      "\n",
      "    accuracy                           0.84       891\n",
      "   macro avg       0.84      0.82      0.83       891\n",
      "weighted avg       0.84      0.84      0.84       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, train_pred_rf))\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, train_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Interpret the Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "      Feature  Importance\n",
      "8       Title    0.316531\n",
      "1         Sex    0.273235\n",
      "0      Pclass    0.137186\n",
      "6  FamilySize    0.079037\n",
      "5   Has_Cabin    0.065737\n",
      "3        Fare    0.052792\n",
      "2         Age    0.038798\n",
      "4    Embarked    0.024210\n",
      "7     IsAlone    0.012474\n"
     ]
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': x_train.columns,\n",
    "    'Importance': random_forest.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick One Small Decision Tree from the Random Forest and Explain It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'small_tree.pdf'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick the first tree from the random forest\n",
    "tree_ = random_forest.estimators_[0]\n",
    "\n",
    "# Visualize the decision tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "dot_data = export_graphviz(tree_, out_file=None, \n",
    "                           feature_names=x_train.columns,  \n",
    "                           class_names=['Died', 'Survived'],  \n",
    "                           filled=True, rounded=True,  \n",
    "                           special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(\"small_tree\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Top Five Important Features to Do a Decision Tree Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy with Top 5 Features: 83.28%\n"
     ]
    }
   ],
   "source": [
    "# Get top 5 important features\n",
    "top_features = feature_importances['Feature'].head(5).tolist()\n",
    "\n",
    "# Train a decision tree using these top 5 features\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=4)\n",
    "x_train_top = x_train[top_features]\n",
    "decision_tree.fit(x_train_top, y_train)\n",
    "\n",
    "# Predict and evaluate the decision tree model\n",
    "train_pred_tree = decision_tree.predict(x_train_top)\n",
    "print(f\"Decision Tree Accuracy with Top 5 Features: {round(accuracy_score(y_train, train_pred_tree) * 100, 2)}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Elaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
